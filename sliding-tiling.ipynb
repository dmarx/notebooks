{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e851a-4b84-458d-b138-f7e56d917212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install einops matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c6e77-3841-49af-8098-86569a48b0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git commit -am \"wrapped parameters\"; git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1729c-a227-4541-a288-a55df38510b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['STABILITY_KEY']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b5816-1031-49b1-b018-30da4a2610fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "import io\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from stability_sdk import client\n",
    "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
    "\n",
    "import torch\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from einops import rearrange\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from itertools import chain\n",
    "\n",
    "def multiplex(latents: torch.Tensor, K: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Rearrange the latents tensor into a KxK grid using the einops rearrange function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    latents: torch.Tensor\n",
    "        The latent tensors to be rearranged.\n",
    "    K: int\n",
    "        The grid size for rearrangement.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The rearranged latents in a KxK grid.\n",
    "    \"\"\"\n",
    "    return rearrange(latents, '(b k1 k2) h w c -> b (k1 h) (k2 w) c', k1=K, k2=K)\n",
    "\n",
    "\n",
    "def demultiplex(images: torch.Tensor, K: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Rearrange the images tensor back from a KxK grid using the einops rearrange function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: torch.Tensor\n",
    "        The image tensors to be rearranged.\n",
    "    K: int\n",
    "        The grid size for rearrangement.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        The rearranged images from a KxK grid back to their original shape.\n",
    "    \"\"\"\n",
    "    return rearrange(images, ' (k1 h) (k2 w) c -> (k1 k2) h w c', k1=K, k2=K)\n",
    "\n",
    "\n",
    "\n",
    "# Set up our connection to the API.\n",
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
    "    verbose=True, # Print debug messages.\n",
    "    engine=\"stable-diffusion-v1-5\", # Set the engine to use for generation.\n",
    "    # Available engines: stable-diffusion-v1 stable-diffusion-v1-5 stable-diffusion-512-v2-0 stable-diffusion-768-v2-0\n",
    "    # stable-diffusion-512-v2-1 stable-diffusion-768-v2-1 stable-diffusion-xl-beta-v2-2-2 stable-inpainting-v1-0 stable-inpainting-512-v2-0\n",
    "    upscale_engine=\"stable-diffusion-x4-latent-upscaler\",\n",
    ")\n",
    "\n",
    "\n",
    "def generate_image(**kargs):\n",
    "    # Set up our initial generation parameters.\n",
    "    if not 'seed' in kargs:\n",
    "        kargs['seed'] = random.randrange(0, 4294967295)\n",
    "    success=False\n",
    "    while not success:\n",
    "        answers = stability_api.generate(\n",
    "            **kargs\n",
    "        )\n",
    "\n",
    "        # Set up our warning to print to the console if the adult content classifier is tripped.\n",
    "        # If adult content classifier is not tripped, save generated images.\n",
    "        for resp in answers:\n",
    "            for artifact in resp.artifacts:\n",
    "                if artifact.finish_reason == generation.FILTER:\n",
    "                    warnings.warn(\n",
    "                        \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                        #\"Please modify the prompt and try again.\"\n",
    "                        \"Trying again.\"\n",
    "                    )\n",
    "                    kargs['seed']+=1\n",
    "                    break\n",
    "                    \n",
    "                if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                    success=True\n",
    "                    img = Image.open(io.BytesIO(artifact.binary))\n",
    "                    #img.save(str(artifact.seed)+ \".png\") # Save our generated images with their seed number as the filename.\n",
    "                    return img, kargs['seed']\n",
    "\n",
    "            \n",
    "def upscale_image(**kargs):\n",
    "    # Set up our initial generation parameters.\n",
    "    if not 'seed' in kargs:\n",
    "        kargs['seed'] = random.randrange(0, 4294967295)\n",
    "    success=False\n",
    "    while not success:\n",
    "        answers = stability_api.upscale(\n",
    "            **kargs\n",
    "        )\n",
    "        # Set up our warning to print to the console if the adult content classifier is tripped.\n",
    "        # If adult content classifier is not tripped, save generated images.\n",
    "        for resp in answers:\n",
    "            for artifact in resp.artifacts:\n",
    "                if artifact.finish_reason == generation.FILTER:\n",
    "                    warnings.warn(\n",
    "                        \"Your request activated the API's safety filters and could not be processed.\"\n",
    "                        #\"Please modify the prompt and try again.\"\n",
    "                        \"trying again...\"\n",
    "                    )\n",
    "                    kargs['seed']+=1\n",
    "                    break\n",
    "\n",
    "                if artifact.type == generation.ARTIFACT_IMAGE:\n",
    "                    success=True\n",
    "                    img = Image.open(io.BytesIO(artifact.binary))\n",
    "                    #img.save(str(artifact.seed)+ \".png\") # Save our generated images with their seed number as the filename.\n",
    "                    return img, kargs['seed']\n",
    "\n",
    "            \n",
    "def image_to_grid(img: Image.Image, k: int = 4, downsample: bool = True) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert an image to a grid by rearranging it into a KxK grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: PIL.Image.Image\n",
    "        The input image to convert to a grid.\n",
    "    k: int, optional (default=4)\n",
    "        The size of the grid (KxK).\n",
    "    downsample: bool, optional (default=True)\n",
    "        Whether to downsample the image before creating the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PIL.Image.Image\n",
    "        The image arranged in a KxK grid.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The input image can be downscaled before creating the grid.\n",
    "    - The resulting grid will have dimensions (k, k) times smaller than the original image.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> image_grid = image_to_grid(image, k=4, downsample=True)\n",
    "    \"\"\"\n",
    "\n",
    "    if downsample:\n",
    "        h, w = img.size\n",
    "        img = img.resize((h // k, w // k))\n",
    "\n",
    "    imlist = [np.array(img)] * (k ** 2)\n",
    "    gridded = multiplex(imlist, K=k)\n",
    "    image_grid = Image.fromarray(np.squeeze(gridded.astype(np.uint8)))\n",
    "\n",
    "    return image_grid\n",
    "\n",
    "\n",
    "\n",
    "def partition_grid(images: list, n_frozen: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Partition the grid of images into frozen and dynamic partitions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: list\n",
    "        List of images in the grid.\n",
    "    n_frozen: int or None, optional (default=None)\n",
    "        Number of images to keep fixed as frozen. If None, defaults to the square root of the total number of images.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple containing the mask image representing the frozen partition, the list of images in the frozen partition,\n",
    "        and the list of images in the dynamic partition.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The frozen partition contains the fixed images that will not change during processing.\n",
    "    - The dynamic partition contains the images that will be subject to modifications or transformations.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> mask, frozen_partition, dynamic_partition = partition_grid(images)\n",
    "    \"\"\"\n",
    "    K = int(np.sqrt(len(images)))\n",
    "\n",
    "    if n_frozen is None:\n",
    "        n_frozen = K\n",
    "\n",
    "    frozen_partition = []\n",
    "    dynamic_partition = []\n",
    "    mask_images = []\n",
    "\n",
    "    for i, im in enumerate(images):\n",
    "        if i < n_frozen:\n",
    "            mask = np.ones_like(im) * 255\n",
    "            frozen_partition.append(im)\n",
    "        else:\n",
    "            mask = np.zeros_like(im)\n",
    "            dynamic_partition.append(im)\n",
    "        mask_images.append(mask)\n",
    "\n",
    "    mask_image = multiplex(mask_images, K)\n",
    "    mask_image = Image.fromarray(np.squeeze(mask_image))\n",
    "\n",
    "    return mask_image, frozen_partition, dynamic_partition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a71b3e-002f-4156-b2e0-cf8fab41ea68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#here's how everything ties together. I feel like there's still more opportunity to make this more readable, maintainable, or useful.\n",
    "\n",
    "\n",
    "def generate_init_grid(\n",
    "    seed,\n",
    "    diffusion_params\n",
    "):\n",
    "    # generate anchor image for init grid\n",
    "    img, seed = generate_image(\n",
    "        prompt=diffusion_params['prompt'],\n",
    "        steps=diffusion_params['steps'],\n",
    "        cfg_scale=diffusion_params['cfg_scale'],\n",
    "        width=diffusion_params['width'],\n",
    "        height=diffusion_params['height'],\n",
    "        sampler=diffusion_params['sampler'],\n",
    "        seed=seed,\n",
    "        samples=1,\n",
    "    )\n",
    "    # build init grid\n",
    "    image_grid = image_to_grid(img)\n",
    "    return image_grid, seed\n",
    "\n",
    "\n",
    "#########################################################\n",
    "\n",
    "def step_image_grid(\n",
    "    image_grid,\n",
    "    k,\n",
    "    diffusion_params,\n",
    "    seed=None,\n",
    "    prev_img=None,\n",
    "):\n",
    "\n",
    "    # apply diffusion step to image grid\n",
    "    image_grid2, seed = generate_image(\n",
    "        init_image = image_grid,\n",
    "        start_schedule=diffusion_params['start_schedule'],\n",
    "        ###################################\n",
    "        prompt=diffusion_params['prompt'],\n",
    "        steps=diffusion_params['steps'],\n",
    "        cfg_scale=diffusion_params['cfg_scale'],\n",
    "        width=diffusion_params['width'],\n",
    "        height=diffusion_params['height'],\n",
    "        sampler=diffusion_params['sampler'],\n",
    "        seed=seed,\n",
    "        samples=1,\n",
    "    )\n",
    "\n",
    "    # upscale generation\n",
    "    image_grid3, seed = upscale_image(\n",
    "        init_image = image_grid2,\n",
    "        seed=seed,\n",
    "        #########################\n",
    "        prompt=diffusion_params['prompt'],\n",
    "        steps=diffusion_params['steps'],\n",
    "        cfg_scale=diffusion_params['cfg_scale'],\n",
    "        width=diffusion_params['width']*4,\n",
    "    )\n",
    "\n",
    "\n",
    "    imlist3 = demultiplex(np.array(image_grid3), K=k) # (16, 512, 512, 3)\n",
    "    \n",
    "    num_fixed=0\n",
    "    if prev_img is not None:\n",
    "        num_fixed=1\n",
    "        imlist3 = list(imlist3)\n",
    "        #imlist3 = [np.array(prev_img)[None, :]] + imlist3\n",
    "        imlist3 = [np.array(prev_img)] + imlist3\n",
    "        imlist3 = np.array(imlist3)\n",
    "\n",
    "    # sort grid images\n",
    "\n",
    "    im_vectors = rearrange(imlist3, \"b h w c -> b (h w c)\") # (16, 786432)\n",
    "    dmat = pdist(im_vectors, metric='cosine') # 120\n",
    "    dmat2 = squareform(dmat) # 16 16\n",
    "    distance_matrix = dmat2[:]\n",
    "    np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "    \n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix[num_fixed:, num_fixed:])\n",
    "    sorted_order = torch.cat([torch.arange(num_fixed), torch.as_tensor(col_indices + num_fixed)])\n",
    "    images = imlist3[sorted_order] # images.shape\n",
    "    images = [Image.fromarray(v) for v in images]  \n",
    "    \n",
    "    if prev_img is not None:\n",
    "        images = images[1:]\n",
    "\n",
    "    return images, seed\n",
    "    \n",
    "def process_images(images, k, frame_idx):\n",
    "\n",
    "    frozen_partition, dynamic_partition = images[:-k], images[-k:]\n",
    "\n",
    "    for img in frozen_partition:\n",
    "        img_path = f\"frame_{frame_idx:04}.png\"\n",
    "        print(img_path)\n",
    "        display(img)\n",
    "        img.save(img_path)\n",
    "        frame_idx+=1\n",
    "    prev_img = img\n",
    "\n",
    "    next_grid_images = []\n",
    "    for _ in range(k):\n",
    "        next_grid_images.extend(dynamic_partition)\n",
    "    imlist = [np.array(im) for im in next_grid_images]\n",
    "    next_grid = multiplex(imlist, K=k)\n",
    "    image_grid = Image.fromarray(np.squeeze(next_grid.astype(np.uint8)))\n",
    "\n",
    "    # I think we need to shrink the new grid, since it's now at upscaled resolution\n",
    "    print(image_grid.size)\n",
    "\n",
    "    image_grid = image_grid.resize((512,512))\n",
    "    return image_grid, frame_idx, prev_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "diffusion_params = {\n",
    "    \"start_schedule\": 0.2,\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"samples\": 1,\n",
    "    \"sampler\": generation.SAMPLER_K_DPMPP_2M\n",
    "}\n",
    "\n",
    "seed=992446758\n",
    "frame_idx=0\n",
    "k=4\n",
    "\n",
    "image_grid, seed = generate_init_grid(seed, diffusion_params)\n",
    "images, seed = step_image_grid(image_grid, k, seed=seed, diffusion_params=diffusion_params)\n",
    "image_grid, frame_idx, prev_img = process_images(images, k, frame_idx)\n",
    "\n",
    "grid_iterations = 10\n",
    "for j in range(grid_iterations):\n",
    "    seed+=1\n",
    "    images, seed = step_image_grid(image_grid=image_grid, k=k, prev_img=prev_img, seed=seed, diffusion_params=diffusion_params)\n",
    "    image_grid, frame_idx, prev_img = process_images(images, k, frame_idx)\n",
    "\n",
    "#for im in images:\n",
    "#    display(im)\n",
    "\n",
    "### to do: rinse and repeat to build up an animation from frozen frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d565b-c93f-4f5a-97dc-2128b38507ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47784114-49a1-44b3-beb5-130d2d508162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[v.shape for v in imlist3]\n",
    "#len(imlist3)\n",
    "#np.array(prev_img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87168f51-7e2f-446e-9a63-28ff1b059093",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fca80e-6797-4033-8016-04fd57624fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up our connection to the API.\n",
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'], # API Key reference.\n",
    "    verbose=True, # Print debug messages.\n",
    "    engine=\"stable-diffusion-v1-5\", # Set the engine to use for generation.\n",
    "    # Available engines: stable-diffusion-v1 stable-diffusion-v1-5 stable-diffusion-512-v2-0 stable-diffusion-768-v2-0\n",
    "    # stable-diffusion-512-v2-1 stable-diffusion-768-v2-1 stable-diffusion-xl-beta-v2-2-2 stable-inpainting-v1-0 stable-inpainting-512-v2-0\n",
    "    upscale_engine=\"stable-diffusion-x4-latent-upscaler\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d15ff4-e770-4f1d-8716-716f93ddef49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = generate_image(\n",
    "    prompt=\"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    seed=992446758, # If a seed is provided, the resulting generated image will be deterministic.\n",
    "                    # What this means is that as long as all generation parameters remain the same, you can always recall the same image simply by generating it again.\n",
    "                    # Note: This isn't quite the case for CLIP Guided generations, which we tackle in the CLIP Guidance documentation.\n",
    "    steps=30, # Amount of inference steps performed on image generation. Defaults to 30.\n",
    "    cfg_scale=8.0, # Influences how strongly your generation is guided to match your prompt.\n",
    "                   # Setting this value higher increases the strength in which it tries to match your prompt.\n",
    "                   # Defaults to 7.0 if not specified.\n",
    "    width=512, # Generation width, defaults to 512 if not included.\n",
    "    height=512, # Generation height, defaults to 512 if not included.\n",
    "    samples=1, # Number of images to generate, defaults to 1 if not included.\n",
    "    sampler=generation.SAMPLER_K_DPMPP_2M # Choose which sampler we want to denoise our generation with.\n",
    "                                                 # Defaults to k_dpmpp_2m if not specified. Clip Guidance only supports ancestral samplers.\n",
    "                                                 # (Available Samplers: ddim, plms, k_euler, k_euler_ancestral, k_heun, k_dpm_2, k_dpm_2_ancestral, k_dpmpp_2s_ancestral, k_lms, k_dpmpp_2m, k_dpmpp_sde)\n",
    ")\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3dedc-e90d-43de-932f-361a981d4b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_grid = image_to_grid(img)\n",
    "image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876790c-87a5-4f28-abc7-f77f87b38a2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed=12345678\n",
    "\n",
    "# apply diffusion step to image grid\n",
    "image_grid2 = generate_image(\n",
    "    init_image = image_grid,\n",
    "    start_schedule=0.2,\n",
    "    #########################\n",
    "    prompt=\"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    steps=30,\n",
    "    cfg_scale=8.0,\n",
    "    width=512,\n",
    "    height=512,\n",
    "    samples=1,\n",
    "    seed=seed,\n",
    "    sampler=generation.SAMPLER_K_DPMPP_2M\n",
    ")\n",
    "\n",
    "# upscale generation\n",
    "image_grid3 = upscale_image(\n",
    "    init_image = image_grid2,\n",
    "    #start_schedule=0.2,\n",
    "    #########################\n",
    "    prompt=\"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    steps=30,\n",
    "    cfg_scale=8.0,\n",
    "    width=512*4,\n",
    "    #height=512,\n",
    "    #samples=1,\n",
    "    seed=seed,\n",
    "    #sampler=generation.SAMPLER_K_DPMPP_2M\n",
    ")\n",
    "\n",
    "image_grid3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f4713-246b-429c-ac3f-f8faecad2f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "imlist3 = demultiplex(np.array(image_grid3), K=4)\n",
    "\n",
    "#imlist3.shape # (16, 512, 512, 3)\n",
    "\n",
    "im_vectors = rearrange(imlist3, \"b h w c -> b (h w c)\")\n",
    "\n",
    "#im_vectors.shape # (16, 786432)\n",
    "\n",
    "dmat = pdist(im_vectors, metric='cosine')\n",
    "dmat.shape # 120\n",
    "dmat2 = squareform(dmat)\n",
    "dmat2.shape # 16 16\n",
    "\n",
    "distance_matrix = dmat2[:]\n",
    "np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "\n",
    "num_fixed=0\n",
    "\n",
    "row_indices, col_indices = linear_sum_assignment(distance_matrix[num_fixed:, num_fixed:])\n",
    "\n",
    "# Add the fixed indices back to get the final sorted order\n",
    "sorted_order = torch.cat([torch.arange(num_fixed), torch.as_tensor(col_indices + num_fixed)])\n",
    "\n",
    "images = imlist3[sorted_order] # images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d5f19-60b1-48c7-ad5f-c18208462102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad35cd-c304-4e91-a047-99a81b35cc10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = [Image.fromarray(v) for v in images]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb260e3-605b-4d19-8c49-d683bd2eeea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "mask, frozen_partition, dynamic_partition = partition_grid(images)\n",
    "\n",
    "#mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84957674-66a4-4514-a4bf-ce61f8f3f37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for im in images:\n",
    "    display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636dbc5-424e-44eb-a65c-16455235e41e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76ebe8-627e-4b89-8bda-2acf40ffbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: let's add transforms i guess? do it without transforms first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602815a-4806-470e-bf93-da65d5fb3db0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df224d-2252-4429-9d6f-44f503326e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# chatgpt guessing at how to loop this.\n",
    "\n",
    "num_rounds = 5  # Number of rounds of diffusion and animation generation\n",
    "num_frozen_frames = 6  # Number of frozen frames per round\n",
    "\n",
    "frozen_frames = deepcopy(frozen_partition)  # Initialize the frozen frames with initial frozen partition\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"Generating Animation - Round {round + 1}\")\n",
    "\n",
    "    # Set the initial image grid as the current frozen frames\n",
    "    initial_image_grid = image_to_grid(frozen_frames, k=4, downsample=False)\n",
    "\n",
    "    # Apply diffusion step to the image grid\n",
    "    diffusion_params[\"init_image\"] = initial_image_grid\n",
    "    diffused_image_grid = generate_image(diffusion_params)\n",
    "\n",
    "    # Upscale the diffused image\n",
    "    upscale_params[\"init_image\"] = diffused_image_grid\n",
    "    upscaled_image_grid = upscale_image(upscale_params)\n",
    "\n",
    "    # Demultiplex the upscaled image grid\n",
    "    demultiplexed_images = demultiplex(np.array(upscaled_image_grid), K=4)\n",
    "\n",
    "    # Calculate pairwise cosine distances\n",
    "    image_vectors = rearrange(demultiplexed_images, \"b h w c -> b (h w c)\")\n",
    "    distance_matrix = pdist(image_vectors, metric='cosine')\n",
    "    distance_matrix = squareform(distance_matrix)\n",
    "    np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "    # Perform TSP sort with the appropriate number of fixed frames\n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix[num_frozen_frames:, num_frozen_frames:])\n",
    "    sorted_order = torch.cat([torch.arange(num_frozen_frames), torch.as_tensor(col_indices + num_frozen_frames)])\n",
    "    sorted_images = demultiplexed_images[sorted_order]\n",
    "\n",
    "    # Update the frozen frames with the desired number of frames\n",
    "    frozen_frames = sorted_images[:num_frozen_frames]\n",
    "\n",
    "    # Display or save the generated frames as needed\n",
    "    for frame in sorted_images:\n",
    "        display(Image.fromarray(frame))\n",
    "\n",
    "    print(\"Round Complete\\n\")\n",
    "\n",
    "print(\"Animation Generation Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439e0fb-38ca-4272-a353-4e5de590d4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's try that again\n",
    "\n",
    "# def image_to_grid(images: list, k: int = 4, downsample: bool = False) -> Image.Image:\n",
    "#     \"\"\"\n",
    "#     Convert a list of images to a grid by rearranging them into a KxK grid.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     images: list\n",
    "#         The input list of images to convert to a grid.\n",
    "#     k: int, optional (default=4)\n",
    "#         The size of the grid (KxK).\n",
    "#     downsample: bool, optional (default=False)\n",
    "#         Whether to downsample the images before creating the grid.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     PIL.Image.Image\n",
    "#         The images arranged in a KxK grid.\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     - The input images can be downsampled before creating the grid.\n",
    "#     - The resulting grid will have dimensions (k, k) times smaller than the original images.\n",
    "#     \"\"\"\n",
    "#     if downsample:\n",
    "#         resized_images = [Image.fromarray(image).resize((image.shape[0] // k, image.shape[1] // k)) for image in images]\n",
    "#     else:\n",
    "#         resized_images = [Image.fromarray(image) for image in images]\n",
    "\n",
    "#     gridded = multiplex(resized_images, K=k)\n",
    "#     image_grid = Image.fromarray(np.squeeze(gridded.astype(np.uint8)))\n",
    "\n",
    "#     return image_grid\n",
    "\n",
    "def image_to_grid(images: list, k: int = 4, downsample: bool = False) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert a list of images to a grid by rearranging them into a KxK grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: list\n",
    "        The input list of images to convert to a grid.\n",
    "    k: int, optional (default=4)\n",
    "        The size of the grid (KxK).\n",
    "    downsample: bool, optional (default=False)\n",
    "        Whether to downsample the images before creating the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PIL.Image.Image\n",
    "        The images arranged in a KxK grid.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The input images can be downsampled before creating the grid.\n",
    "    - The resulting grid will have dimensions (k, k) times smaller than the original images.\n",
    "    \"\"\"\n",
    "    if downsample:\n",
    "        resized_images = [np.array(image.resize((image.size[0] // k, image.size[1] // k))) for image in images]\n",
    "    else:\n",
    "        resized_images = [np.array(image) for image in images]\n",
    "\n",
    "    gridded = multiplex(resized_images, K=k)\n",
    "    image_grid = Image.fromarray(np.squeeze(gridded.astype(np.uint8)))\n",
    "\n",
    "    return image_grid\n",
    "\n",
    "\n",
    "# Set up our connection to the API.\n",
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'],\n",
    "    verbose=True,\n",
    "    engine=\"stable-diffusion-v1-5\",\n",
    "    upscale_engine=\"stable-diffusion-x4-latent-upscaler\"\n",
    ")\n",
    "\n",
    "# Generate initial image\n",
    "initial_img_params = {\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"seed\": 992446758,\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"samples\": 1,\n",
    "    \"sampler\": generation.SAMPLER_K_DPMPP_2M\n",
    "}\n",
    "\n",
    "initial_image = generate_image(**initial_img_params)\n",
    "\n",
    "# Convert initial image to grid\n",
    "initial_image_grid = image_to_grid([initial_image], k=4, downsample=False)\n",
    "\n",
    "seed = 12345678\n",
    "\n",
    "# Apply diffusion step to the image grid\n",
    "diffusion_params = {\n",
    "    \"init_image\": initial_image_grid,\n",
    "    \"start_schedule\": 0.2,\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"samples\": 1,\n",
    "    \"seed\": seed,\n",
    "    \"sampler\": generation.SAMPLER_K_DPMPP_2M\n",
    "}\n",
    "\n",
    "diffused_image_grid = generate_image(diffusion_params)\n",
    "\n",
    "# Upscale the diffused image\n",
    "# Upscale the diffused image\n",
    "upscale_params = {\n",
    "    \"init_image\": diffused_image_grid,\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512 * 4,\n",
    "    \"seed\": seed,\n",
    "}\n",
    "\n",
    "upscaled_image_grid = upscale_image(upscale_params)\n",
    "\n",
    "# Demultiplex the upscaled image grid\n",
    "demultiplexed_images = demultiplex(np.array(upscaled_image_grid), K=4)\n",
    "\n",
    "# Calculate pairwise cosine distances\n",
    "image_vectors = rearrange(demultiplexed_images, \"b h w c -> b (h w c)\")\n",
    "distance_matrix = pdist(image_vectors, metric='cosine')\n",
    "distance_matrix = squareform(distance_matrix)\n",
    "np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "num_fixed = 0\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"Generating Animation - Round {round + 1}\")\n",
    "\n",
    "    # Set the initial image grid as the current frozen frames\n",
    "    initial_image_grid = image_to_grid(frozen_frames, k=4, downsample=False)\n",
    "\n",
    "    # Apply diffusion step to the image grid\n",
    "    diffusion_params[\"init_image\"] = initial_image_grid\n",
    "    diffused_image_grid = generate_image(diffusion_params)\n",
    "\n",
    "    # Upscale the diffused image\n",
    "    upscale_params[\"init_image\"] = diffused_image_grid\n",
    "    upscaled_image_grid = upscale_image(upscale_params)\n",
    "\n",
    "    # Demultiplex the upscaled image grid\n",
    "    demultiplexed_images = demultiplex(np.array(upscaled_image_grid), K=4)\n",
    "\n",
    "    # Calculate pairwise cosine distances\n",
    "    image_vectors = rearrange(demultiplexed_images, \"b h w c -> b (h w c)\")\n",
    "    distance_matrix = pdist(image_vectors, metric='cosine')\n",
    "    distance_matrix = squareform(distance_matrix)\n",
    "    np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "    # Perform TSP sort with the appropriate number of fixed frames\n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix[num_fixed:, num_fixed:])\n",
    "    sorted_order = torch.cat([torch.arange(num_fixed), torch.as_tensor(col_indices + num_fixed)])\n",
    "    sorted_images = demultiplexed_images[sorted_order]\n",
    "\n",
    "    # Update the frozen frames with the desired number of frames\n",
    "    frozen_frames = sorted_images[:num_frozen_frames]\n",
    "\n",
    "    # Display or save the generated frames as needed\n",
    "    for frame in sorted_images:\n",
    "        display(Image.fromarray(frame))\n",
    "\n",
    "    print(\"Round Complete\\n\")\n",
    "\n",
    "print(\"Animation Generation Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecb832-f7cd-456a-9f1e-ac47513f0547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def image_to_grid(images: list, k: int = 4, downsample: bool = False) -> Image.Image:\n",
    "#     \"\"\"\n",
    "#     Convert a list of images to a grid by rearranging them into a KxK grid.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     images: list\n",
    "#         The input list of images to convert to a grid.\n",
    "#     k: int, optional (default=4)\n",
    "#         The size of the grid (KxK).\n",
    "#     downsample: bool, optional (default=False)\n",
    "#         Whether to downsample the images before creating the grid.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     PIL.Image.Image\n",
    "#         The images arranged in a KxK grid.\n",
    "\n",
    "#     Notes\n",
    "#     -----\n",
    "#     - The input images can be downsampled before creating the grid.\n",
    "#     - The resulting grid will have dimensions (k, k) times smaller than the original images.\n",
    "#     \"\"\"\n",
    "#     if downsample:\n",
    "#         resized_images = [np.array(image.resize((image.size[0] // k, image.size[1] // k))) for image in images]\n",
    "#     else:\n",
    "#         resized_images = [np.array(image) for image in images]\n",
    "\n",
    "#     gridded = multiplex(resized_images, K=k)\n",
    "#     image_grid = Image.fromarray(np.squeeze(gridded.astype(np.uint8)))\n",
    "\n",
    "#     return image_grid\n",
    "\n",
    "def image_to_grid(images: list, k: int = 4, downsample: bool = False) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert a list of images to a grid by rearranging them into a KxK grid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    images: list\n",
    "        The input list of images to convert to a grid.\n",
    "    k: int, optional (default=4)\n",
    "        The size of the grid (KxK).\n",
    "    downsample: bool, optional (default=False)\n",
    "        Whether to downsample the images before creating the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PIL.Image.Image\n",
    "        The images arranged in a KxK grid.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The input images can be downsampled before creating the grid.\n",
    "    - The resulting grid will have dimensions (k, k) times smaller than the original images.\n",
    "    \"\"\"\n",
    "    if downsample:\n",
    "        resized_images = [np.array(image.resize((image.size[0] // k, image.size[1] // k))) for image in images]\n",
    "    else:\n",
    "        resized_images = [np.array(image) for image in images]\n",
    "\n",
    "    if len(resized_images) == 1:\n",
    "        return Image.fromarray(resized_images[0])\n",
    "\n",
    "    gridded = multiplex(resized_images, K=k)\n",
    "    image_grid = Image.fromarray(np.squeeze(gridded.astype(np.uint8)))\n",
    "\n",
    "    return image_grid\n",
    "\n",
    "\n",
    "# Set up our connection to the API.\n",
    "stability_api = client.StabilityInference(\n",
    "    key=os.environ['STABILITY_KEY'],\n",
    "    verbose=True,\n",
    "    engine=\"stable-diffusion-v1-5\",\n",
    "    upscale_engine=\"stable-diffusion-x4-latent-upscaler\"\n",
    ")\n",
    "\n",
    "# Generate initial image\n",
    "initial_img_params = {\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"seed\": 992446758,\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"samples\": 1,\n",
    "    \"sampler\": generation.SAMPLER_K_DPMPP_2M\n",
    "}\n",
    "\n",
    "initial_image = generate_image(**initial_img_params)\n",
    "\n",
    "# Convert initial image to grid\n",
    "initial_image_grid = image_to_grid([initial_image], k=4, downsample=False)\n",
    "\n",
    "seed = 12345678\n",
    "\n",
    "# Apply diffusion step to the image grid\n",
    "diffusion_params = {\n",
    "    \"init_image\": initial_image_grid,\n",
    "    \"start_schedule\": 0.2,\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"samples\": 1,\n",
    "    \"seed\": seed,\n",
    "    \"sampler\": generation.SAMPLER_K_DPMPP_2M\n",
    "}\n",
    "\n",
    "diffused_image_grid = generate_image(**diffusion_params)\n",
    "\n",
    "# Upscale the diffused image\n",
    "upscale_params = {\n",
    "    \"init_image\": diffused_image_grid,\n",
    "    \"prompt\": \"expansive landscape rolling greens with blue daisies and weeping willow trees under a blue alien sky, artstation, masterful, ghibli\",\n",
    "    \"steps\": 30,\n",
    "    \"cfg_scale\": 8.0,\n",
    "    \"width\": 512 * 4,\n",
    "    \"seed\": seed,\n",
    "}\n",
    "\n",
    "upscaled_image_grid = upscale_image(**upscale_params)\n",
    "\n",
    "# Demultiplex the upscaled image grid\n",
    "demultiplexed_images = demultiplex(np.array(upscaled_image_grid), K=4)\n",
    "\n",
    "# Calculate pairwise cosine distances\n",
    "image_vectors = rearrange(demultiplexed_images, \"b h w c -> b (h w c)\")\n",
    "distance_matrix = pdist(image_vectors, metric='cosine')\n",
    "distance_matrix = squareform(distance_matrix)\n",
    "np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "num_fixed = 0\n",
    "\n",
    "all_frames = []\n",
    "\n",
    "for round in range(num_rounds):\n",
    "    print(f\"Generating Animation - Round {round + 1}\")\n",
    "\n",
    "    # Set the initial image grid as the current frozen frames\n",
    "    #initial_image_grid = image_to_grid(frozen_frames, k=4, downsample=False)\n",
    "    im_seq = []\n",
    "    for _ in range(4): # range(len(frozen_frames)): ?\n",
    "        im_seq.extend(frozen_frames)\n",
    "    im_seq = [Image.fromarray(f) for f in im_seq]\n",
    "    #initial_image_grid = image_to_grid(im_seq, k=4, downsample=False)\n",
    "    #initial_image_grid = image_to_grid(im_seq, k=4, downsample=(round>0))\n",
    "    initial_image_grid = image_to_grid(im_seq, k=4, downsample=True)\n",
    "    print(initial_image_grid.size)\n",
    "\n",
    "    # Apply diffusion step to the image grid\n",
    "    diffusion_params[\"init_image\"] = initial_image_grid\n",
    "    diffused_image_grid = generate_image(**diffusion_params)\n",
    "\n",
    "    # Upscale the diffused image\n",
    "    upscale_params[\"init_image\"] = diffused_image_grid\n",
    "    upscaled_image_grid = upscale_image(**upscale_params)\n",
    "\n",
    "    # Demultiplex the upscaled image grid\n",
    "    demultiplexed_images = demultiplex(np.array(upscaled_image_grid), K=4)\n",
    "\n",
    "    # Calculate pairwise cosine distances\n",
    "    image_vectors = rearrange(demultiplexed_images, \"b h w c -> b (h w c)\")\n",
    "    distance_matrix = pdist(image_vectors, metric='cosine')\n",
    "    distance_matrix = squareform(distance_matrix)\n",
    "    np.fill_diagonal(distance_matrix, 1)\n",
    "\n",
    "    # Perform TSP sort with the appropriate number of fixed frames\n",
    "    row_indices, col_indices = linear_sum_assignment(distance_matrix[num_fixed:, num_fixed:])\n",
    "    sorted_order = torch.cat([torch.arange(num_fixed), torch.as_tensor(col_indices + num_fixed)])\n",
    "    sorted_images = demultiplexed_images[sorted_order]\n",
    "\n",
    "    # Update the frozen frames with the desired number of frames\n",
    "    frozen_frames = sorted_images[:num_frozen_frames]\n",
    "\n",
    "    # Display or save the generated frames as needed\n",
    "    #for frame in sorted_images:\n",
    "    for frame in frozen_frames:\n",
    "        frame = Image.fromarray(frame)\n",
    "        display(frame)\n",
    "        all_frames.append(frame)\n",
    "\n",
    "    print(\"Round Complete\\n\")\n",
    "\n",
    "print(\"Animation Generation Complete\")\n",
    "# ```\n",
    "\n",
    "# In this updated code, the `image_to_grid()` function has been modified to handle resizing and grid creation outside the loop, ensuring consistent image shapes for each iteration. Additionally, the code for generating animation frames has been provided, including the freezing of frames, diffusion steps, and TSP-based sorting of images.\n",
    "\n",
    "# Please note that the code assumes the availability of the required functions and libraries, and it may need further adjustments based on the specifics of your environment and requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fd475-242b-41d3-8243-9410faf63dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_seq[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15BNHICpOOXg"
      },
      "source": [
        "# Stable Diffusion KLMC2 Animation\n",
        "\n",
        "<div>\n",
        "<img src=\"https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/a432c21c-bb12-4f38-b5e2-1c12a3c403f6/Animated-Logo_1.gif\" width=\"150\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Notebook by [Katherine Crowson](https://twitter.com/RiversHaveWings)\n",
        "\n",
        "Sponsored by [StabilityAI](https://twitter.com/stabilityai)\n",
        "\n",
        "Generate animations with [Stable Diffusion](https://stability.ai/blog/stable-diffusion-public-release) 1.4, using the [KLMC2 discretization of underdamped Langevin dynamics](https://arxiv.org/abs/1807.09382). The notebook is largely inspired by [Ajay Jain](https://twitter.com/ajayj_) and [Ben Poole](https://twitter.com/poolio)'s paper [Journey to the BAOAB-limit](https://www.ajayjain.net/journey)&mdash;thank you so much for it!\n",
        "\n",
        "---\n",
        "\n",
        "## Modifications Provenance\n",
        "\n",
        "Original notebook URL - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1m8ovBpO2QilE2o4O-p2PONSwqGn4_x2G)\n",
        "\n",
        "Features and QOL Modifications by [David Marx](https://twitter.com/DigThatData) - [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dmarx/notebooks/blob/main/Stable_Diffusion_KLMC2_Animation.ipynb)\n",
        "\n",
        "* Keyframed prompts and settings\n",
        "* Multiprompt conditioning w independent prompt schedules\n",
        "* Set seed for deterministic output\n",
        "* Mount Google Drive\n",
        "* Faster Setup\n",
        "* Init image\n",
        "* Alt-checkpoint loading consistent w/deforum\n",
        "* Set output filename\n",
        "* Fancy GPU info\n",
        "* Video embed optional\n",
        "* Cheaper default runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/dmarx/proj/notebooks/_venv/bin/python\n"
          ]
        }
      ],
      "source": [
        "!which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "Ty3IOeXbLzvc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Check GPU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgpu_info\u001b[39m():\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "#@title Check GPU\n",
        "#!nvidia-smi\n",
        "\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "def gpu_info():\n",
        "    outv = subprocess.run([\n",
        "        'nvidia-smi',\n",
        "            # these lines concatenate into a single query string\n",
        "            '--query-gpu='\n",
        "            'timestamp,'\n",
        "            'name,'\n",
        "            'utilization.gpu,'\n",
        "            'utilization.memory,'\n",
        "            'memory.used,'\n",
        "            'memory.free,'\n",
        "            ,\n",
        "        '--format=csv'\n",
        "        ],\n",
        "        stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "\n",
        "    header, rec = outv.split('\\n')[:-1]\n",
        "    return pd.DataFrame({' '.join(k.strip().split('.')).capitalize():v for k,v in zip(header.split(','), rec.split(','))}, index=[0]).T\n",
        "\n",
        "gpu_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "kelHR9VM1-hg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_102751/3805173390.py:14: UserWarning: Unable to import `google`, assuming this means we're using a local runtime\n",
            "  warnings.warn(\"Unable to import `google`, assuming this means we're using a local runtime\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/huggingface_hub (from -r klmc2/requirements.txt (line 26))\n",
            "  Cloning https://github.com/huggingface/huggingface_hub to /tmp/pip-req-build-nofotrof\n",
            "  Running command git clone -q https://github.com/huggingface/huggingface_hub /tmp/pip-req-build-nofotrof\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 887.4 MB 66 kB/s  eta 0:00:016\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 8.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchsde\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.24.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 9.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 9.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 486 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 552 kB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 8.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting clip\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "Collecting open_clip_torch\n",
            "  Downloading open_clip_torch-2.9.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 8.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[K     |████████████████████████████████| 800 kB 7.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting kornia\n",
            "  Downloading kornia-0.6.9-py2.py3-none-any.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 4.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting k-diffusion\n",
            "  Downloading k_diffusion-0.0.12-py3-none-any.whl (25 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 7.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting napm\n",
            "  Downloading napm-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting keyframed\n",
            "  Downloading keyframed-0.2.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in ./_venv/lib/python3.9/site-packages (from huggingface-hub==0.12.0.dev0->-r klmc2/requirements.txt (line 26)) (23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "\u001b[K     |████████████████████████████████| 661 kB 5.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting tqdm>=4.42.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in ./_venv/lib/python3.9/site-packages (from ftfy->-r klmc2/requirements.txt (line 12)) (0.2.6)\n",
            "Collecting nbconvert\n",
            "  Downloading nbconvert-7.2.8-py3-none-any.whl (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 6.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting notebook\n",
            "  Downloading notebook-6.5.2-py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 4.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting ipywidgets\n",
            "  Downloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\n",
            "\u001b[K     |████████████████████████████████| 137 kB 7.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 8.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jupyter-console\n",
            "  Downloading jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: ipykernel in ./_venv/lib/python3.9/site-packages (from jupyter->-r klmc2/requirements.txt (line 7)) (6.20.2)\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jsonmerge\n",
            "  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 8.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting clip-anytorch\n",
            "  Downloading clip_anytorch-2.5.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 6.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting resize-right\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Collecting clean-fid\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.0 MB 8.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 8.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sortedcontainers\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 15.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 55 kB/s  eta 0:00:011   |██▊                             | 46.7 MB 2.8 MB/s eta 0:03:06     |███████████████████████████▌    | 479.6 MB 8.4 MB/s eta 0:00:10     |██████████████████████████████▏ | 525.2 MB 7.6 MB/s eta 0:00:05\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 7.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 8.3 MB/s eta 0:00:013\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./_venv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r klmc2/requirements.txt (line 1)) (44.1.1)\n",
            "Collecting wheel\n",
            "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Collecting gdown<5.0.0,>=4.4.0\n",
            "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting loguru<0.7.0,>=0.6.0\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 13.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 10.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 317 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 7.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 7.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 8.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six in ./_venv/lib/python3.9/site-packages (from gdown<5.0.0,>=4.4.0->napm->-r klmc2/requirements.txt (line 24)) (1.16.0)\n",
            "Collecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 8.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 4.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 9.3 MB/s eta 0:00:011\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in ./_venv/lib/python3.9/site-packages (from pandas->-r klmc2/requirements.txt (line 8)) (2.8.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[K     |████████████████████████████████| 499 kB 8.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboardX>=2.2\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 6.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 8.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting fsspec[http]>2021.06.0\n",
            "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 7.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting lightning-utilities!=0.4.0,>=0.3.0\n",
            "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 7.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 9.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 7.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 10.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 9.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting protobuf==3.20.*\n",
            "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 6.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting trampoline>=0.1.2\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Collecting boltons>=20.2.1\n",
            "  Downloading boltons-21.0.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 6.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 7.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: psutil in ./_venv/lib/python3.9/site-packages (from accelerate->k-diffusion->-r klmc2/requirements.txt (line 22)) (5.9.4)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: nest-asyncio in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (1.5.6)\n",
            "Requirement already satisfied: comm>=0.1.1 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.1.6)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (7.4.9)\n",
            "Requirement already satisfied: pyzmq>=17 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (25.0.0)\n",
            "Requirement already satisfied: tornado>=6.1 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (6.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (5.8.1)\n",
            "Requirement already satisfied: ipython>=7.23.1 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (8.8.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in ./_venv/lib/python3.9/site-packages (from ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (1.6.5)\n",
            "Requirement already satisfied: stack-data in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.6.2)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (2.14.0)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.11 in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (3.0.36)\n",
            "Requirement already satisfied: pickleshare in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: backcall in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: decorator in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./_venv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.18.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./_venv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.8.3)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in ./_venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (5.1.3)\n",
            "Requirement already satisfied: entrypoints in ./_venv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in ./_venv/lib/python3.9/site-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (2.6.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./_venv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.7.0)\n",
            "Collecting jupyterlab-widgets~=3.0\n",
            "  Downloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 7.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting widgetsnbextension~=4.0\n",
            "  Downloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 10.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jsonschema>2.4.0\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting markupsafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting nbformat>=5.1\n",
            "  Downloading nbformat-5.7.3-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pandocfilters>=1.4.1\n",
            "  Downloading pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting jupyterlab-pygments\n",
            "  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 8.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nbclient>=0.5.0\n",
            "  Downloading nbclient-0.7.2-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 514 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting importlib-metadata>=3.6\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting tinycss2\n",
            "  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting mistune<3,>=2.0.3\n",
            "  Downloading mistune-2.0.4-py2.py3-none-any.whl (24 kB)\n",
            "Collecting bleach\n",
            "  Downloading bleach-5.0.1-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 6.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting defusedxml\n",
            "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.11.0-py3-none-any.whl (6.6 kB)\n",
            "Collecting fastjsonschema\n",
            "  Downloading fastjsonschema-2.16.2-py3-none-any.whl (22 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting nbclassic>=0.4.7\n",
            "  Downloading nbclassic-0.4.8-py3-none-any.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 112 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting terminado>=0.8.3\n",
            "  Downloading terminado-0.17.1-py3-none-any.whl (17 kB)\n",
            "Collecting Send2Trash>=1.8.0\n",
            "  Downloading Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
            "Collecting prometheus-client\n",
            "  Downloading prometheus_client-0.15.0-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 6.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting argon2-cffi\n",
            "  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
            "Collecting notebook-shim>=0.1.0\n",
            "  Downloading notebook_shim-0.2.2-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-server>=1.8\n",
            "  Downloading jupyter_server-2.1.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 6.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting jupyter-server-terminals\n",
            "  Downloading jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)\n",
            "Collecting jupyter-events>=0.4.0\n",
            "  Downloading jupyter_events-0.6.3-py3-none-any.whl (18 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 6.5 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting anyio<4,>=3.1.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting python-json-logger>=2.0.4\n",
            "  Downloading python_json_logger-2.0.4-py3-none-any.whl (7.8 kB)\n",
            "Collecting rfc3986-validator>=0.1.1\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting rfc3339-validator\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Collecting isoduration\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting uri-template\n",
            "  Downloading uri_template-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting jsonpointer>1.13\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting webcolors>=1.11\n",
            "  Downloading webcolors-1.12-py3-none-any.whl (9.9 kB)\n",
            "Collecting fqdn\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting argon2-cffi-bindings\n",
            "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cffi>=1.0.1\n",
            "  Downloading cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 8.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pycparser\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 9.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting arrow>=0.15.0\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 4.0 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting PySocks!=1.5.7,>=1.5.6\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Collecting tifffile>=2019.7.26\n",
            "  Downloading tifffile-2022.10.10-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 8.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
            "  Downloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 7.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting networkx>=2.2\n",
            "  Downloading networkx-3.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 8.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting imageio>=2.4.1\n",
            "  Downloading imageio-2.24.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 3.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pure-eval in ./_venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./_venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./_venv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r klmc2/requirements.txt (line 7)) (1.2.0)\n",
            "Collecting Click!=8.0.0,>=7.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.13.0-py2.py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 8.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting appdirs>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 6.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 3.5 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Using legacy 'setup.py install' for clip, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for jsonmerge, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for pathtools, since package 'wheel' is not installed.\n",
            "Building wheels for collected packages: huggingface-hub\n",
            "  Building wheel for huggingface-hub (PEP 517) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for huggingface-hub: filename=huggingface_hub-0.12.0.dev0-py3-none-any.whl size=189535 sha256=5588fda05d35d64b94f8b8644a7342610feefa739b55e2f0f2d2008104a3818c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oi35o8cc/wheels/93/69/5f/f223aa8b97fb23c12890d8b51ddf430f8fae5d49241474a063\n",
            "Successfully built huggingface-hub\n",
            "Installing collected packages: pyrsistent, attrs, pycparser, jsonschema, fastjsonschema, arrow, zipp, webencodings, webcolors, uri-template, soupsieve, rfc3986-validator, rfc3339-validator, nbformat, markupsafe, jsonpointer, isoduration, idna, fqdn, cffi, wheel, tinycss2, terminado, sniffio, pyyaml, python-json-logger, pandocfilters, nbclient, mistune, jupyterlab-pygments, jinja2, importlib-metadata, defusedxml, bleach, beautifulsoup4, argon2-cffi-bindings, websocket-client, Send2Trash, prometheus-client, nvidia-cublas-cu11, nbconvert, jupyter-server-terminals, jupyter-events, argon2-cffi, anyio, urllib3, typing-extensions, smmap, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, multidict, jupyter-server, frozenlist, charset-normalizer, certifi, yarl, torch, requests, PySocks, pillow, numpy, notebook-shim, ipython-genutils, gitdb, async-timeout, aiosignal, widgetsnbextension, trampoline, tqdm, torchvision, tifffile, setproctitle, sentry-sdk, scipy, regex, qtpy, PyWavelets, protobuf, pathtools, networkx, nbclassic, jupyterlab-widgets, imageio, GitPython, ftfy, fsspec, filelock, docker-pycreds, Click, boltons, appdirs, antlr4-python3-runtime, aiohttp, wandb, torchsde, torchmetrics, torchdiffeq, tokenizers, tensorboardX, sortedcontainers, sentencepiece, scikit-image, resize-right, qtconsole, pytz, omegaconf, notebook, loguru, lightning-utilities, kornia, jupyter-console, jsonmerge, ipywidgets, huggingface-hub, gdown, einops, clip-anytorch, clean-fid, accelerate, transformers, pytorch-lightning, pandas, open-clip-torch, ninja, napm, keyframed, k-diffusion, jupyter, clip, braceexpand\n",
            "    Running setup.py install for pathtools ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for jsonmerge ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for clip ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed Click-8.1.3 GitPython-3.1.30 PySocks-1.7.1 PyWavelets-1.4.1 Send2Trash-1.8.0 accelerate-0.15.0 aiohttp-3.8.3 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 anyio-3.6.2 appdirs-1.4.4 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 async-timeout-4.0.2 attrs-22.2.0 beautifulsoup4-4.11.1 bleach-5.0.1 boltons-21.0.0 braceexpand-0.1.7 certifi-2022.12.7 cffi-1.15.1 charset-normalizer-2.1.1 clean-fid-0.1.35 clip-0.2.0 clip-anytorch-2.5.0 defusedxml-0.7.1 docker-pycreds-0.4.0 einops-0.6.0 fastjsonschema-2.16.2 filelock-3.9.0 fqdn-1.5.1 frozenlist-1.3.3 fsspec-2022.11.0 ftfy-6.1.1 gdown-4.6.0 gitdb-4.0.10 huggingface-hub-0.12.0.dev0 idna-3.4 imageio-2.24.0 importlib-metadata-6.0.0 ipython-genutils-0.2.0 ipywidgets-8.0.4 isoduration-20.11.0 jinja2-3.1.2 jsonmerge-1.9.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-1.0.0 jupyter-console-6.4.4 jupyter-events-0.6.3 jupyter-server-2.1.0 jupyter-server-terminals-0.4.4 jupyterlab-pygments-0.2.2 jupyterlab-widgets-3.0.5 k-diffusion-0.0.12 keyframed-0.2.1 kornia-0.6.9 lightning-utilities-0.5.0 loguru-0.6.0 markupsafe-2.1.2 mistune-2.0.4 multidict-6.0.4 napm-1.0.1 nbclassic-0.4.8 nbclient-0.7.2 nbconvert-7.2.8 nbformat-5.7.3 networkx-3.0 ninja-1.11.1 notebook-6.5.2 notebook-shim-0.2.2 numpy-1.24.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.3.0 open-clip-torch-2.9.3 pandas-1.5.2 pandocfilters-1.5.0 pathtools-0.1.2 pillow-9.4.0 prometheus-client-0.15.0 protobuf-3.20.1 pycparser-2.21 pyrsistent-0.19.3 python-json-logger-2.0.4 pytorch-lightning-1.8.6 pytz-2022.7.1 pyyaml-6.0 qtconsole-5.4.0 qtpy-2.3.0 regex-2022.10.31 requests-2.28.2 resize-right-0.0.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 scikit-image-0.19.3 scipy-1.10.0 sentencepiece-0.1.97 sentry-sdk-1.13.0 setproctitle-1.3.2 smmap-5.0.0 sniffio-1.3.0 sortedcontainers-2.4.0 soupsieve-2.3.2.post1 tensorboardX-2.5.1 terminado-0.17.1 tifffile-2022.10.10 tinycss2-1.2.1 tokenizers-0.13.2 torch-1.13.1 torchdiffeq-0.2.3 torchmetrics-0.11.0 torchsde-0.2.5 torchvision-0.14.1 tqdm-4.64.1 trampoline-0.1.2 transformers-4.25.1 typing-extensions-4.4.0 uri-template-1.2.0 urllib3-1.26.14 wandb-0.13.9 webcolors-1.12 webencodings-0.5.1 websocket-client-1.4.2 wheel-0.38.4 widgetsnbextension-4.0.5 yarl-1.8.2 zipp-3.11.0\n"
          ]
        }
      ],
      "source": [
        "#@title Install Dependencies\n",
        "\n",
        "# @markdown Your runtime will automatically restart after running this cell.\n",
        "# @markdown You should only need to run this cell when setting up a new runtime. After future runtime restarts,\n",
        "# @markdown you should be able to skip this cell.\n",
        "\n",
        "import warnings\n",
        "\n",
        "probably_using_colab = False\n",
        "try:\n",
        "    import google\n",
        "    probably_using_colab = True\n",
        "except ImportError:\n",
        "    warnings.warn(\"Unable to import `google`, assuming this means we're using a local runtime\")\n",
        "\n",
        "if probably_using_colab:\n",
        "    !pip install ftfy einops braceexpand requests transformers clip open_clip_torch omegaconf pytorch-lightning kornia k-diffusion ninja omegaconf\n",
        "    !pip install -U git+https://github.com/huggingface/huggingface_hub\n",
        "    !pip install napm keyframed\n",
        "    # !pip install -v -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers\n",
        "    exit() # oh is this a way to restart the runtime? clever!\n",
        "else:\n",
        "    !pip install -r klmc2/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Path('/content').exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "fJZtXShcPXx5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-17 12:41:17.804 | WARNING  | napm.pseudo_install:make_install_dir:21 - /home/dmarx/.cache/napm/stablediffusion already exists\n",
            "fatal: destination path '/home/dmarx/.cache/napm/stablediffusion' already exists and is not an empty directory.\n",
            "2023-01-17 12:41:17.818 | DEBUG    | napm.pseudo_install:pseudoinstall_git_repo:64 - Added /home/dmarx/.cache/napm/stablediffusion to sys.path\n",
            "2023-01-17 12:41:17.819 | DEBUG    | napm.config:config_path:28 - /home/dmarx/.cache/napm/config.yaml\n",
            "2023-01-17 12:41:17.825 | DEBUG    | napm.config:config_path:28 - /home/dmarx/.cache/napm/config.yaml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "looks like we're not in colab\n"
          ]
        }
      ],
      "source": [
        "# @markdown # Setup Workspace { display-mode: \"form\" }\n",
        "\n",
        "###################\n",
        "# Setup Workspace #\n",
        "###################\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "probably_using_colab = False\n",
        "try:\n",
        "    import google\n",
        "    if Path('/content').exists():\n",
        "        probably_using_colab = True\n",
        "        print(\"looks like we're in colab\")\n",
        "    else:\n",
        "        print(\"looks like we're not in colab\")\n",
        "except ImportError:\n",
        "    warnings.warn(\"Unable to import `google`, assuming this means we're using a local runtime\")\n",
        "\n",
        "\n",
        "mount_gdrive = True # @param {type:'boolean'}\n",
        "\n",
        "# defaults\n",
        "outdir = Path('./frames')\n",
        "if not os.environ.get('XDG_CACHE_HOME'):\n",
        "    os.environ['XDG_CACHE_HOME'] = str(Path('~/.cache').expanduser())\n",
        "\n",
        "if mount_gdrive and probably_using_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    Path('/content/drive/MyDrive/AI/models/.cache/').mkdir(parents=True, exist_ok=True) \n",
        "    os.environ['XDG_CACHE_HOME']='/content/drive/MyDrive/AI/models/.cache'\n",
        "    outdir = Path('/content/drive/MyDrive/AI/klmc2/frames/')\n",
        "\n",
        "# make sure the paths we need exist\n",
        "outdir.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['NAPM_PATH'] = str( Path(os.environ['XDG_CACHE_HOME']) / 'napm' )\n",
        "Path(os.environ['NAPM_PATH']).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "import napm\n",
        "\n",
        "url = 'https://github.com/Stability-AI/stablediffusion'\n",
        "napm.pseudoinstall_git_repo(url, add_install_dir_to_path=True)\n",
        "\n",
        "\n",
        "##### Moved from model loading cell\n",
        "\n",
        "if probably_using_colab:\n",
        "    models_path = \"/content/models\" #@param {type:\"string\"}\n",
        "else:\n",
        "    models_path =  os.environ['XDG_CACHE_HOME']\n",
        "\n",
        "if mount_gdrive and probably_using_colab:\n",
        "  models_path_gdrive = \"/content/drive/MyDrive/AI/models\" #@param {type:\"string\"}\n",
        "  models_path = models_path_gdrive\n",
        "\n",
        "if not Path(models_path).exists():\n",
        "  Path(models_path).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "cellView": "form",
        "id": "y2jXKIf2ZkT8"
      },
      "outputs": [],
      "source": [
        "# @markdown # Imports and Definitions { display-mode: \"form\" }\n",
        "\n",
        "###########\n",
        "# imports #\n",
        "###########\n",
        "\n",
        "import napm\n",
        "\n",
        "from base64 import b64encode\n",
        "from collections import defaultdict\n",
        "from concurrent import futures\n",
        "import math\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "import functorch\n",
        "from IPython import display\n",
        "import k_diffusion as K\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "#sys.path.extend(['./stablediffusion'])\n",
        "from ldm.util import instantiate_from_config\n",
        "\n",
        "from requests.exceptions import HTTPError\n",
        "import huggingface_hub\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from keyframed import Curve, ParameterGroup, Keyframe\n",
        "import math\n",
        "\n",
        "\n",
        "#########################\n",
        "# Define useful globals #\n",
        "#########################\n",
        "\n",
        "cpu = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "############################\n",
        "\n",
        "model_dir_str=str(Path(os.environ['XDG_CACHE_HOME']))\n",
        "\n",
        "sdmodelid2hfrepo = {\n",
        "    \"sd-v1-4\":\"CompVis/stable-diffusion-v-1-4-original\",\n",
        "    \"sd-v1-5\":\"runwayml/stable-diffusion-v1-5\",\n",
        "}\n",
        "\n",
        "sdmodelid2hfckpt = {\n",
        "    \"sd-v1-4\":\"sd-v1-4.ckpt\",\n",
        "    \"sd-v1-5\":\"v1-5-pruned-emaonly.ckpt\",\n",
        "}\n",
        "\n",
        "sdmodelid2yamlurl = {\n",
        "    \"sd-v1-4\":\"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\",\n",
        "    \"sd-v1-5\":\"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\",\n",
        "}\n",
        "\n",
        "sdmodelid2ckptstyle = {\n",
        "    \"sd-v1-4\":\"compvis\",\n",
        "    \"sd-v1-5\":\"compvis\",\n",
        "}\n",
        "\n",
        "############################\n",
        "\n",
        "vaemodelid2hfrepo = {\n",
        "    \"vae-ft-mse-840k\":\"stabilityai/sd-vae-ft-mse-original\",\n",
        "    \"vae-ft-ema-560k\":\"stabilityai/sd-vae-ft-ema-original\",\n",
        "    #\"vae-orig\":,\n",
        "}\n",
        "\n",
        "vaemodelid2hfckpt = {\n",
        "    \"vae-ft-mse-840k\":\"vae-ft-mse-840000-ema-pruned.ckpt\",\n",
        "    \"vae-ft-ema-560k\":\"vae-ft-ema-560000-ema-pruned.ckpt\",\n",
        "    #\"vae-orig\":,\n",
        "}\n",
        "\n",
        "vaemodelid2yamlurl = {\n",
        "    \"vae-ft-mse-840k\":\"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/models/first_stage_models/kl-f8/config.yaml\",\n",
        "    \"vae-ft-ema-560k\":\"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/models/first_stage_models/kl-f8/config.yaml\",\n",
        "    #\"vae-orig\":\"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/models/first_stage_models/kl-f8/config.yaml\",\n",
        "}\n",
        "\n",
        "\n",
        "##############################\n",
        "# Define necessary functions #\n",
        "##############################\n",
        "\n",
        "class Prompt:\n",
        "    def __init__(\n",
        "        self,\n",
        "        text,\n",
        "        weight_schedule,\n",
        "        ease_in=None,\n",
        "        ease_out=None,\n",
        "        ):\n",
        "      c = sd_model.get_learned_conditioning([text])\n",
        "      self.text=text\n",
        "      self.encoded=c\n",
        "      self.weight=Curve(\n",
        "          weight_schedule, \n",
        "          default_interpolation='linear', \n",
        "          ease_in=ease_in, \n",
        "          ease_out=ease_out)\n",
        "\n",
        "##################\n",
        "\n",
        "class NormalizingCFGDenoiser(nn.Module):\n",
        "    def __init__(self, model, g):\n",
        "        super().__init__()\n",
        "        self.inner_model = model\n",
        "        self.g = g\n",
        "        self.eps_norms = defaultdict(lambda: (0, 0))\n",
        "\n",
        "    def mean_sq(self, x):\n",
        "        return x.pow(2).flatten(1).mean(1)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_eps_norm(self, eps, sigma):\n",
        "        sigma = sigma[0].item()\n",
        "        eps_norm = self.mean_sq(eps).mean()\n",
        "        eps_norm_avg, count = self.eps_norms[sigma]\n",
        "        eps_norm_avg = eps_norm_avg * count / (count + 1) + eps_norm / (count + 1)\n",
        "        self.eps_norms[sigma] = (eps_norm_avg, count + 1)\n",
        "        return eps_norm_avg\n",
        "\n",
        "    def forward(self, x, sigma, uncond, cond, g):\n",
        "        x_in = torch.cat([x] * 2)\n",
        "        sigma_in = torch.cat([sigma] * 2)\n",
        "        cond_in = torch.cat([uncond, cond])\n",
        "\n",
        "        denoised = self.inner_model(x_in, sigma_in, cond=cond_in)\n",
        "        eps = K.sampling.to_d(x_in, sigma_in, denoised)\n",
        "        eps_uc, eps_c = eps.chunk(2)\n",
        "        eps_norm = self.update_eps_norm(eps, sigma).sqrt()\n",
        "        c = eps_c - eps_uc\n",
        "        cond_scale = g * eps_norm / self.mean_sq(c).sqrt()\n",
        "        eps_final = eps_uc + c * K.utils.append_dims(cond_scale, x.ndim)\n",
        "        return x - eps_final * K.utils.append_dims(sigma, eps.ndim)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_mcmc_klmc2(\n",
        "    model, x, \n",
        "    sigma_min, sigma, sigma_max, \n",
        "    n, \n",
        "    hvp_method='reverse', \n",
        "    callback=None, \n",
        "    disable=None, \n",
        "    prompts=None,\n",
        "    settings=None, # g, h, gamma, alpha, tau, prompt\n",
        "):\n",
        "    s_in = x.new_ones([x.shape[0]])\n",
        "    sigma = torch.tensor(sigma, device=x.device)\n",
        "    sigmas = K.sampling.get_sigmas_karras(6, sigma_min, sigma.item(), device=x.device)[:-1]\n",
        "\n",
        "    uc = sd_model.get_learned_conditioning([''])\n",
        "    extra_args = {'uncond': uc}\n",
        "    v = torch.randn_like(x) * sigma # ... I guess?\n",
        "\n",
        "    for i in trange(n, disable=disable):\n",
        "\n",
        "        h = settings[i]['h']\n",
        "        gamma = settings[i]['gamma']\n",
        "        alpha = settings[i]['alpha']\n",
        "        tau = settings[i]['tau']\n",
        "\n",
        "        h = torch.tensor(h, device=x.device)\n",
        "        gamma = torch.tensor(gamma, device=x.device)\n",
        "        alpha = torch.tensor(alpha, device=x.device)\n",
        "        tau = torch.tensor(tau, device=x.device)\n",
        "\n",
        "        # Model helper functions\n",
        "\n",
        "        def hvp_fn_forward_functorch(x, sigma, v, **extra_args):\n",
        "            def grad_fn(x, sigma):\n",
        "                denoised = model(x, sigma * s_in, **extra_args)\n",
        "                return (x - denoised) + alpha * x\n",
        "            jvp_fn = lambda v: functorch.jvp(grad_fn, (x, sigma), (v, torch.zeros_like(sigma)))\n",
        "            grad, jvp_out = functorch.vmap(jvp_fn)(v)\n",
        "            return grad[0], jvp_out\n",
        "\n",
        "        def hvp_fn_reverse(x, sigma, v, **extra_args):\n",
        "            def grad_fn(x, sigma):\n",
        "                denoised = model(x, sigma * s_in, **extra_args)\n",
        "                return (x - denoised) + alpha * x\n",
        "            vjps = []\n",
        "            with torch.enable_grad():\n",
        "                x_ = x.clone().requires_grad_()\n",
        "                grad = grad_fn(x_, sigma)\n",
        "                for k, item in enumerate(v):\n",
        "                    vjp_out = torch.autograd.grad(grad, x_, item, retain_graph=k < len(v) - 1)[0]\n",
        "                    vjps.append(vjp_out)\n",
        "            return grad, torch.stack(vjps)\n",
        "\n",
        "        def hvp_fn_zero(x, sigma, v, **extra_args):\n",
        "            def grad_fn(x, sigma):\n",
        "                denoised = model(x, sigma * s_in, **extra_args)\n",
        "                return (x - denoised) + alpha * x\n",
        "            return grad_fn(x, sigma), torch.zeros_like(v)\n",
        "\n",
        "        def hvp_fn_fake(x, sigma, v, **extra_args):\n",
        "            def grad_fn(x, sigma):\n",
        "                denoised = model(x, sigma * s_in, **extra_args)\n",
        "                return (x - denoised) + alpha * x\n",
        "            return grad_fn(x, sigma), (1 + alpha) * v\n",
        "\n",
        "        hvp_fns = {'forward-functorch': hvp_fn_forward_functorch,\n",
        "                  'reverse': hvp_fn_reverse,\n",
        "                  'zero': hvp_fn_zero,\n",
        "                  'fake': hvp_fn_fake}\n",
        "\n",
        "        hvp_fn = hvp_fns[hvp_method]\n",
        "\n",
        "        # KLMC2 helper functions\n",
        "        def psi_0(gamma, t):\n",
        "            return torch.exp(-gamma * t)\n",
        "\n",
        "        def psi_1(gamma, t):\n",
        "            return -torch.expm1(-gamma * t) / gamma\n",
        "\n",
        "        def psi_2(gamma, t):\n",
        "            return (torch.expm1(-gamma * t) + gamma * t) / gamma ** 2\n",
        "\n",
        "        def phi_2(gamma, t_):\n",
        "            t = t_.double()\n",
        "            out = (torch.exp(-gamma * t) * (torch.expm1(gamma * t) - gamma * t)) / gamma ** 2\n",
        "            return out.to(t_)\n",
        "\n",
        "        def phi_3(gamma, t_):\n",
        "            t = t_.double()\n",
        "            out = (torch.exp(-gamma * t) * (2 + gamma * t + torch.exp(gamma * t) * (gamma * t - 2))) / gamma ** 3\n",
        "            return out.to(t_)\n",
        "\n",
        "\n",
        "        # Compute model outputs and sample noise\n",
        "        x_trapz = torch.linspace(0, h, 1001, device=x.device)\n",
        "        y_trapz = [fun(gamma, x_trapz) for fun in (psi_0, psi_1, phi_2, phi_3)]\n",
        "        noise_cov = torch.tensor([[torch.trapz(y_trapz[i] * y_trapz[j], x=x_trapz) for j in range(4)] for i in range(4)], device=x.device)\n",
        "        noise_v, noise_x, noise_v2, noise_x2 = torch.distributions.MultivariateNormal(x.new_zeros([4]), noise_cov).sample(x.shape).unbind(-1)\n",
        "            \n",
        "        extra_args['g']=g\n",
        "\n",
        "        # loop over prompts and aggregate gradients for multicond\n",
        "        grad = torch.zeros_like(x)\n",
        "        h2_v = torch.zeros_like(x)\n",
        "        h2_noise_v2 = torch.zeros_like(x)\n",
        "        h2_noise_x2 = torch.zeros_like(x)\n",
        "        wt_norm = 0\n",
        "        for prompt in prompts:\n",
        "            wt = prompt.weight[i]\n",
        "            if wt == 0:\n",
        "                continue\n",
        "            wt_norm += wt\n",
        "            wt = torch.tensor(wt, device=x.device)\n",
        "            extra_args['cond'] = prompt.encoded\n",
        "\n",
        "            # Estimate gradient and hessian\n",
        "            grad_, (h2_v_, h2_noise_v2_, h2_noise_x2_) = hvp_fn(\n",
        "                x, sigma, torch.stack([v, noise_v2, noise_x2]),\n",
        "                **extra_args\n",
        "            )\n",
        "\n",
        "            grad = grad + grad_ * wt \n",
        "            h2_v = h2_v + h2_v_ * wt\n",
        "            h2_noise_v2 = h2_noise_v2 + h2_noise_v2_ * wt\n",
        "            h2_noise_x2 = h2_noise_x2 + h2_noise_x2_ * wt\n",
        "\n",
        "        # Normalize gradient to magnitude it'd have if just single prompt w/ wt=1.\n",
        "        # simplifies multicond w/o deep frying image or adding hyperparams\n",
        "        grad = grad / wt_norm \n",
        "        h2_v = h2_v / wt_norm\n",
        "        h2_noise_v2 = h2_noise_v2 / wt_norm\n",
        "        h2_noise_x2 = h2_noise_x2 / wt_norm\n",
        "        \n",
        "\n",
        "        # DPM-Solver++(2M) refinement steps\n",
        "        x_refine = x\n",
        "        use_dpm = True\n",
        "        old_denoised = None\n",
        "        for j in range(len(sigmas) - 1):\n",
        "            if j == 0:\n",
        "                denoised = x_refine - grad\n",
        "            else:\n",
        "                denoised = model(x_refine, sigmas[j] * s_in, **extra_args)\n",
        "            dt_ode = sigmas[j + 1] - sigmas[j]\n",
        "            if not use_dpm or old_denoised is None or sigmas[j + 1] == 0:\n",
        "                eps = K.sampling.to_d(x_refine, sigmas[j], denoised)\n",
        "                x_refine = x_refine + eps * dt_ode\n",
        "            else:\n",
        "                h_ode = sigmas[j].log() - sigmas[j + 1].log()\n",
        "                h_last = sigmas[j - 1].log() - sigmas[j].log()\n",
        "                fac = h_ode / (2 * h_last)\n",
        "                denoised_d = (1 + fac) * denoised - fac * old_denoised\n",
        "                eps = K.sampling.to_d(x_refine, sigmas[j], denoised_d)\n",
        "                x_refine = x_refine + eps * dt_ode\n",
        "            old_denoised = denoised\n",
        "        if callback is not None:\n",
        "            callback({'i': i, 'denoised': x_refine})\n",
        "\n",
        "        # Update the chain\n",
        "        noise_std = (2 * gamma * tau * sigma ** 2).sqrt()\n",
        "        v_next = 0 + psi_0(gamma, h) * v - psi_1(gamma, h) * grad - phi_2(gamma, h) * h2_v + noise_std * (noise_v - h2_noise_v2)\n",
        "        x_next = x + psi_1(gamma, h) * v - psi_2(gamma, h) * grad - phi_3(gamma, h) * h2_v + noise_std * (noise_x - h2_noise_x2)\n",
        "        v, x = v_next, x_next\n",
        "\n",
        "    x = x - grad\n",
        "    return x\n",
        "\n",
        "\n",
        "def show_video(video_path, video_width=512):\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return display.HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "yt3d1hww17ST"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-01-17 12:41:37--  https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1873 (1.8K) [text/plain]\n",
            "Saving to: ‘v1-inference.yaml’\n",
            "\n",
            "v1-inference.yaml   100%[===================>]   1.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-17 12:41:37 (62.1 MB/s) - ‘v1-inference.yaml’ saved [1873/1873]\n",
            "\n",
            "Using config: ./v1-inference.yaml\n",
            "This model requires an authentication token\n",
            "Please ensure you have accepted its terms of service before continuing.\n",
            "Attempting to download sd-v1-4.ckpt...this may take a while\n"
          ]
        }
      ],
      "source": [
        "#@markdown **Select and Load Model**\n",
        "\n",
        "# scavenged from:\n",
        "#   https://github.com/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "import napm\n",
        "from ldm.util import instantiate_from_config\n",
        "\n",
        "\n",
        "model_config = \"v1-inference.yaml\" #@param [\"custom\",\"v1-inference.yaml\"]\n",
        "model_checkpoint =  \"sd-v1-4.ckpt\" #@param [\"custom\",\"sd-v1-4-full-ema.ckpt\",\"sd-v1-4.ckpt\",\"sd-v1-3-full-ema.ckpt\",\"sd-v1-3.ckpt\",\"sd-v1-2-full-ema.ckpt\",\"sd-v1-2.ckpt\",\"sd-v1-1-full-ema.ckpt\",\"sd-v1-1.ckpt\", \"robo-diffusion-v1.ckpt\",\"waifu-diffusion-v1-3.ckpt\"]\n",
        "if model_checkpoint == \"waifu-diffusion-v1-3.ckpt\":\n",
        "    model_checkpoint = \"model-epoch05-float16.ckpt\"\n",
        "custom_config_path = \"\" #@param {type:\"string\"}\n",
        "custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "half_precision = True # check\n",
        "check_sha256 = True #@param {type:\"boolean\"}\n",
        "\n",
        "model_map = {\n",
        "    \"sd-v1-4-full-ema.ckpt\": {\n",
        "        'sha256': '14749efc0ae8ef0329391ad4436feb781b402f4fece4883c7ad8d10556d8a36a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-4-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-4.ckpt\": {\n",
        "        'sha256': 'fe4efff1e174c627256e44ec2991ba279b3816e364b49f9be2abc0b3ff3f8556',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3-full-ema.ckpt\": {\n",
        "        'sha256': '54632c6e8a36eecae65e36cb0595fab314e1a1545a65209f24fde221a8d4b2ca',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/blob/main/sd-v1-3-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-3.ckpt\": {\n",
        "        'sha256': '2cff93af4dcc07c3e03110205988ff98481e86539c51a8098d4f2236e41f7f2f',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-3-original/resolve/main/sd-v1-3.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2-full-ema.ckpt\": {\n",
        "        'sha256': 'bc5086a904d7b9d13d2a7bccf38f089824755be7261c7399d92e555e1e9ac69a',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/blob/main/sd-v1-2-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-2.ckpt\": {\n",
        "        'sha256': '3b87d30facd5bafca1cbed71cfb86648aad75d1c264663c0cc78c7aea8daec0d',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-2-original/resolve/main/sd-v1-2.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1-full-ema.ckpt\": {\n",
        "        'sha256': 'efdeb5dc418a025d9a8cc0a8617e106c69044bc2925abecc8a254b2910d69829',\n",
        "        'url':'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1-full-ema.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"sd-v1-1.ckpt\": {\n",
        "        'sha256': '86cd1d3ccb044d7ba8db743d717c9bac603c4043508ad2571383f954390f3cea',\n",
        "        'url': 'https://huggingface.co/CompVis/stable-diffusion-v-1-1-original/resolve/main/sd-v1-1.ckpt',\n",
        "        'requires_login': True,\n",
        "        },\n",
        "    \"robo-diffusion-v1.ckpt\": {\n",
        "        'sha256': '244dbe0dcb55c761bde9c2ac0e9b46cc9705ebfe5f1f3a7cc46251573ea14e16',\n",
        "        'url': 'https://huggingface.co/nousr/robo-diffusion/resolve/main/models/robo-diffusion-v1.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "    \"model-epoch05-float16.ckpt\": {\n",
        "        'sha256': '26cf2a2e30095926bb9fd9de0c83f47adc0b442dbfdc3d667d43778e8b70bece',\n",
        "        'url': 'https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/model-epoch05-float16.ckpt',\n",
        "        'requires_login': False,\n",
        "        },\n",
        "}\n",
        "\n",
        "# config path\n",
        "ckpt_config_path = custom_config_path if model_config == \"custom\" else os.path.join(models_path, model_config)\n",
        "if os.path.exists(ckpt_config_path):\n",
        "    print(f\"{ckpt_config_path} exists\")\n",
        "else:\n",
        "    #ckpt_config_path = \"./stable-diffusion/configs/stable-diffusion/v1-inference.yaml\"\n",
        "    ckpt_config_path = \"./v1-inference.yaml\"\n",
        "    if not Path(ckpt_config_path).exists():\n",
        "        !wget https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "    \n",
        "print(f\"Using config: {ckpt_config_path}\")\n",
        "\n",
        "# checkpoint path or download\n",
        "ckpt_path = custom_checkpoint_path if model_checkpoint == \"custom\" else os.path.join(models_path, model_checkpoint)\n",
        "ckpt_valid = True\n",
        "if os.path.exists(ckpt_path):\n",
        "    print(f\"{ckpt_path} exists\")\n",
        "elif 'url' in model_map[model_checkpoint]:\n",
        "    url = model_map[model_checkpoint]['url']\n",
        "\n",
        "    # CLI dialogue to authenticate download\n",
        "    if model_map[model_checkpoint]['requires_login']:\n",
        "        print(\"This model requires an authentication token\")\n",
        "        print(\"Please ensure you have accepted its terms of service before continuing.\")\n",
        "\n",
        "        username = input(\"What is your huggingface username?:\")\n",
        "        token = input(\"What is your huggingface token?:\")\n",
        "\n",
        "        _, path = url.split(\"https://\")\n",
        "\n",
        "        url = f\"https://{username}:{token}@{path}\"\n",
        "\n",
        "    # contact server for model\n",
        "    print(f\"Attempting to download {model_checkpoint}...this may take a while\")\n",
        "    ckpt_request = requests.get(url)\n",
        "    request_status = ckpt_request.status_code\n",
        "\n",
        "    # inform user of errors\n",
        "    if request_status == 403:\n",
        "      raise ConnectionRefusedError(\"You have not accepted the license for this model.\")\n",
        "    elif request_status == 404:\n",
        "      raise ConnectionError(\"Could not make contact with server\")\n",
        "    elif request_status != 200:\n",
        "      raise ConnectionError(f\"Some other error has ocurred - response code: {request_status}\")\n",
        "\n",
        "    # write to model path\n",
        "    with open(os.path.join(models_path, model_checkpoint), 'wb') as model_file:\n",
        "        model_file.write(ckpt_request.content)\n",
        "else:\n",
        "    print(f\"Please download model checkpoint and place in {os.path.join(models_path, model_checkpoint)}\")\n",
        "    ckpt_valid = False\n",
        "\n",
        "if check_sha256 and model_checkpoint != \"custom\" and ckpt_valid:\n",
        "    import hashlib\n",
        "    print(\"\\n...checking sha256\")\n",
        "    with open(ckpt_path, \"rb\") as f:\n",
        "        bytes = f.read() \n",
        "        hash = hashlib.sha256(bytes).hexdigest()\n",
        "        del bytes\n",
        "    if model_map[model_checkpoint][\"sha256\"] == hash:\n",
        "        print(\"hash is correct\\n\")\n",
        "    else:\n",
        "        print(\"hash in not correct\\n\")\n",
        "        ckpt_valid = False\n",
        "\n",
        "if ckpt_valid:\n",
        "    print(f\"Using ckpt: {ckpt_path}\")\n",
        "\n",
        "def load_model_from_config(config, ckpt, verbose=False, device='cuda', half_precision=True):\n",
        "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
        "    print(f\"Loading model from {ckpt}\")\n",
        "    pl_sd = torch.load(ckpt, map_location=map_location)\n",
        "    if \"global_step\" in pl_sd:\n",
        "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
        "    sd = pl_sd[\"state_dict\"]\n",
        "    model = instantiate_from_config(config.model)\n",
        "    m, u = model.load_state_dict(sd, strict=False)\n",
        "    if len(m) > 0 and verbose:\n",
        "        print(\"missing keys:\")\n",
        "        print(m)\n",
        "    if len(u) > 0 and verbose:\n",
        "        print(\"unexpected keys:\")\n",
        "        print(u)\n",
        "\n",
        "    if half_precision:\n",
        "        model = model.half().to(device)\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "if ckpt_valid:\n",
        "    local_config = OmegaConf.load(f\"{ckpt_config_path}\")\n",
        "    model = load_model_from_config(local_config, f\"{ckpt_path}\", half_precision=half_precision)\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Disable checkpointing as it is not compatible with the method\n",
        "    for module in model.modules():\n",
        "        if hasattr(module, 'checkpoint'):\n",
        "            module.checkpoint = False\n",
        "        if hasattr(module, 'use_checkpoint'):\n",
        "            module.use_checkpoint = False\n",
        "\n",
        "    sd_model=model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZljSF1ePnBl4"
      },
      "outputs": [],
      "source": [
        "# @title Settings\n",
        "\n",
        "# @markdown The number of frames to sample:\n",
        "n = 150 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown If seed is negative, a random seed will be used\n",
        "seed = -1  # @param {type:\"number\"}\n",
        "\n",
        "init_image = \"\" # @param {type:'string'}\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown The strength of the conditioning on the prompt:\n",
        "g = 0.1 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown The noise level to sample at:\n",
        "sigma = 2.0 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Step size (range 0 to 1):\n",
        "h = 0.1 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Friction (2 is critically damped, lower -> smoother animation):\n",
        "gamma = 1.0 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Quadratic penalty (\"weight decay\") strength:\n",
        "alpha = 0.005 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Temperature (adjustment to the amount of noise added per step):\n",
        "tau = 1.0 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown The HVP method:\n",
        "# @markdown <br><small>`forward-functorch` and `reverse` provide real second derivatives. Compatibility, speed, and memory usage vary by model and xformers configuration.\n",
        "# @markdown `fake` is very fast and low memory but inaccurate. `zero` (fallback to first order KLMC) is not recommended.</small>\n",
        "hvp_method = 'fake' # @param [\"forward-functorch\", \"reverse\", \"fake\", \"zero\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pLTsdGBPXx6"
      },
      "outputs": [],
      "source": [
        "#@title Prompts\n",
        "\n",
        "#  [  \n",
        "#    [\"first prompt will be used to initialize the image\", {time:weight, time:weight...}], \n",
        "#    [\"more prompts if you want\", {...}], \n",
        "#  ...]\n",
        "\n",
        "# if a weight for time=0 isn't specified, the weight is assumed to be zero.\n",
        "\n",
        "\n",
        "prompt_params = [\n",
        "    # FIRST PROMPT INITIALIZES IMAGE\n",
        "    [\"portrait of queen elizabeth at 20 years old\", {0:1, 50:1, 100:0}],\n",
        "    [\"portrait of queen elizabeth at 82 years old\", {50:0, 100:1}],\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hZ0lh-WkdB19"
      },
      "outputs": [],
      "source": [
        "# @title Build prompt and settings objects\n",
        "\n",
        "plot_prompt_weight_curves = True # @param {type: 'boolean'}\n",
        "\n",
        "#################\n",
        "\n",
        "def sin2(t):\n",
        "    return (math.sin(t * math.pi / 2)) ** 2\n",
        "\n",
        "prompts = [\n",
        "    Prompt(text, weight_schedule, ease_in=sin2, ease_out=sin2) \n",
        "    for (text, weight_schedule) in prompt_params\n",
        "]\n",
        "\n",
        "\n",
        "curved_settings = ParameterGroup({\n",
        "    'g':Curve(g),\n",
        "    'sigma':Curve(sigma),\n",
        "    #'g':Curve({0:0.08,50:1.1, 500:1}), # warm up cfg\n",
        "    #'sigma':Curve({0:.25,50:1, 125:1, 200:2, 300:1.5, 500:1.25, 700:1, 800:1, 1000:3}), # warm up noise w init image\n",
        "    'h':Curve(h),\n",
        "    #'h':Curve({0:0.1, 200:0.1, 300:0.13}),\n",
        "    'gamma':Curve(gamma),\n",
        "    'alpha':Curve(alpha),\n",
        "    'tau':Curve(tau),\n",
        "    'seed':Curve(seed),\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "if plot_prompt_weight_curves:\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np \n",
        "\n",
        "\n",
        "    ytot=np.array([0 for _ in range(n)])\n",
        "    for prompt in prompts:#[:3]:\n",
        "      xs = np.array(range(n))\n",
        "      ys = np.array([prompt.weight[x] for x in xs])\n",
        "      ytot=ytot+ys\n",
        "      plt.plot(xs, ys)\n",
        "    plt.title(\"prompt weight schedules\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(xs, ytot)\n",
        "    plt.title(\"sum weight\\n(aka: why weights get normalized)\")\n",
        "    plt.show()\n",
        "\n",
        "    for prompt in prompts:#[:3]:\n",
        "      xs = np.array(range(n))\n",
        "      ys = np.array([prompt.weight[x] for x in xs])\n",
        "      plt.plot(xs, ys/ytot)\n",
        "    plt.title(\"normalized weights\\n(aka: why prompts might seem weighted differently than I asked)\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i-_u1Q0wRqMb"
      },
      "outputs": [],
      "source": [
        "#@title Generate Animation Frames\n",
        "\n",
        "\n",
        "###################\n",
        "\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "\n",
        "###################\n",
        "\n",
        "import random\n",
        "\n",
        "# to do: if random seed, pick one for user and report chosen seed back\n",
        "if seed >= 0:\n",
        "    torch.manual_seed(seed)\n",
        "else:\n",
        "    seed = random.randrange(0, 4294967295)\n",
        "print(f\"using seed: {seed}\")\n",
        "\n",
        "wrappers = {'eps': K.external.CompVisDenoiser, 'v': K.external.CompVisVDenoiser}\n",
        "model_wrap = wrappers[sd_model.parameterization](sd_model)\n",
        "model_wrap_cfg = NormalizingCFGDenoiser(model_wrap, g)\n",
        "sigma_min, sigma_max = model_wrap.sigmas[0].item(), model_wrap.sigmas[-1].item()\n",
        "\n",
        "uc = sd_model.get_learned_conditioning([''])\n",
        "c = prompts[0].encoded\n",
        "extra_args = {'cond': c, 'uncond': uc}\n",
        "\n",
        "def save_image_fn(image, name, i):\n",
        "    pil_image = K.utils.to_pil_image(image)\n",
        "    if i % 10 == 0 or i == n - 1:\n",
        "        print(f'\\nIteration {i}/{n}:')\n",
        "        display.display(pil_image)\n",
        "    if i == n - 1:\n",
        "        print('\\nDone!')\n",
        "    name = outdir / name\n",
        "    pil_image.save(name)\n",
        "\n",
        "# to do: add archival\n",
        "# Clean up old images and video - save them elsewhere before running this if you want to keep them!\n",
        "#for p in Path('.').glob('out_*.png'):\n",
        "for p in outdir.glob('out_*.png'):\n",
        "    p.unlink()\n",
        "Path('out.mp4').unlink(missing_ok=True)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "with torch.cuda.amp.autocast(), futures.ThreadPoolExecutor() as ex:\n",
        "    def callback(info):\n",
        "        i = info['i']\n",
        "        #rgb = vae_model.decode(info['denoised'] / sd_model.scale_factor)\n",
        "        rgb = sd_model.decode_first_stage(info['denoised'] )\n",
        "        ex.submit(save_image_fn, rgb, f'out_{i:05}.png', i)\n",
        "\n",
        "    # Initialize the chain\n",
        "    print('Initializing the chain...')\n",
        "    extra_args['g'] = curved_settings[0]['g']\n",
        "\n",
        "    x = None\n",
        "    if init_image:\n",
        "        if not Path(init_image).exists():\n",
        "            raise FileNotFoundError(f\"Unable to locate init image from path: {init_image}\")\n",
        "        else:\n",
        "            print(\"loading init image\")\n",
        "            from PIL import Image\n",
        "            import numpy as np\n",
        "\n",
        "            init_im_pil = Image.open(init_image)\n",
        "\n",
        "            x_pil = init_im_pil.resize([512,512])\n",
        "            x_np = np.array(x_pil.convert('RGB')).astype(np.float16) / 255.0\n",
        "\n",
        "            #image = np.array(image).astype(np.float16) / 255.0\n",
        "            x = x_np[None].transpose(0, 3, 1, 2)\n",
        "            x = 2.*x - 1.\n",
        "            x = torch.from_numpy(x).to('cuda')\n",
        "            x = sd_model.get_first_stage_encoding(sd_model.encode_first_stage(x))\n",
        "            print(\"init image loaded.\")\n",
        "        \n",
        "    if x is None:\n",
        "        print(\"No init image provided, generating a random init image\")\n",
        "        x = torch.randn([1, 4, 64, 64], device=device) * sigma_max\n",
        "\n",
        "        sigmas_pre = K.sampling.get_sigmas_karras(15, sigma, sigma_max, device=x.device)[:-1]\n",
        "        x = K.sampling.sample_dpmpp_sde(model_wrap_cfg, x, sigmas_pre, extra_args=extra_args)\n",
        "\n",
        "    print('Actually doing the sampling...')\n",
        "    sample_mcmc_klmc2(\n",
        "        model=model_wrap_cfg,\n",
        "        x=x,\n",
        "        sigma_min=sigma_min,\n",
        "        sigma=sigma,\n",
        "        sigma_max=sigma_max,\n",
        "        n=n,\n",
        "        hvp_method=hvp_method,\n",
        "        callback=callback,\n",
        "        prompts=prompts,\n",
        "        settings=curved_settings,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DjwY7XrooLX_"
      },
      "outputs": [],
      "source": [
        "#@title Make the video\n",
        "\n",
        "outdir_str = str(outdir)\n",
        "\n",
        "fps = 20 # @param {type:\"integer\"}\n",
        "out_fname = \"out.mp4\" # @param {type: \"string\"}\n",
        "\n",
        "out_fullpath = str( outdir / out_fname )\n",
        "print(f\"Video will be saved to: {out_fullpath}\")\n",
        "\n",
        "print('\\nMaking the video...\\n')\n",
        "!cd {outdir_str}; ffmpeg -y -r {fps} -i 'out_%*.png' -crf 15 -preset veryslow -pix_fmt yuv420p {out_fname}\n",
        "\n",
        "# @markdown If your video is larger than a few MB, attempting to embed it will probably crash\n",
        "# @markdown the session. If this happens, view the generated video after downloading it first.\n",
        "embed_video = False # @param {type:'boolean'}\n",
        "download_video = True # @param {type:'boolean'}\n",
        "\n",
        "if embed_video:\n",
        "  print('\\nThe video:')\n",
        "  display.display(show_video(out_fullpath))\n",
        "\n",
        "if download_video:\n",
        "  from google.colab import files\n",
        "  files.download(out_fullpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK_GlP_7WJiu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the MIT License { display-mode: \"form\" }\n",
        "\n",
        "# Copyright (c) 2022 Katherine Crowson <crowsonkb@gmail.com>\n",
        "# Copyright (c) 2023 David Marx <david.marx84@gmail.com>\n",
        "# Copyright (c) 2022 deforum and contributors\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('_venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ff1624fd81a21ea709585fb1fdce5419f857f6a9e76cb1632f1b8b574978f9ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
